{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f47d4a8c-195e-4c9c-ade0-97fc93688881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Transform data\n",
    "In this notebook we perform transformations required to get required features for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04f16614-94d5-44fd-86f8-b44e8a901526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set up dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.sql.functions import count, when, isnan, col\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d6d08df-6860-479b-8f50-9d90278a5a28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PopHealthRisk\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a46f6291-d558-41b0-99c9-e1d9cc331990",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet('/Volumes/pophealthrisk/pophealthrisk/pophealthrisk/LLCP2024.parquet', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ffbc4d6-e1db-41dd-ad4c-3b9cb173e5c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Transform data\n",
    "First we will clean variables that contain values that are interpreted as missing or 0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c1c692c-ef21-45db-a787-1e1e2e9ae06b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_variable(df, col, null_vals):\n",
    "    df = df.withColumn(\n",
    "        col+'_clean',\n",
    "            when(df[col].isin(null_vals), np.nan).otherwise(df[col]))\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "703a2945-6728-46fb-adbe-25f9e1961284",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n|_AGEG5YR_clean|count|\n+--------------+-----+\n|           1.0|29692|\n|           6.0|28968|\n|           4.0|28804|\n|           5.0|30899|\n|           8.0|34936|\n|           NaN| 8310|\n|          10.0|47701|\n|           7.0|31698|\n|          13.0|41756|\n|          11.0|44774|\n|           2.0|23705|\n|           9.0|43387|\n|          12.0|36803|\n|           3.0|26237|\n+--------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# check function works as expected\n",
    "df=clean_variable(df,'_AGEG5YR',[14])\n",
    "df.groupBy('_AGEG5YR_clean').count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "909f2ab9-0b43-43ef-b703-f00529fa343f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "variables_to_clean={\"EDUCA\":[9],'INCOME3':[77,99], '_SMOKER3':[9], 'DRNKANY6':[7,9],'CHILDREN':[99],'HHADULT':[0,77,88,99],'_RFHLTH':[9]}\n",
    "#BMI does not require cleaning\n",
    "for v in variables_to_clean:\n",
    "    df=clean_variable(df,v,variables_to_clean[v])\n",
    "\n",
    "df = df.withColumn(\n",
    "        'CHILDREN_clean_mod',\n",
    "            when(df['CHILDREN_clean'].isin([88]), 0).otherwise(df['CHILDREN_clean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dcd0013-c11e-4d6c-ae2b-08003e059dda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+\n|CHILDREN_clean_mod| count|\n+------------------+------+\n|              14.0|    13|\n|              NULL|  5606|\n|              23.0|     1|\n|               0.0|336299|\n|              32.0|     2|\n|              22.0|     3|\n|              29.0|     1|\n|              18.0|     1|\n|               1.0| 48206|\n|               6.0|   695|\n|              25.0|     1|\n|              15.0|     5|\n|               4.0|  5672|\n|              41.0|     1|\n|               5.0|  1854|\n|               8.0|   127|\n|              81.0|    12|\n|              17.0|     2|\n|              20.0|     2|\n|              82.0|     3|\n+------------------+------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# check that modifying CHILDREN_clean worked\n",
    "df.groupBy('CHILDREN_clean_mod').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7375ff72-a346-492d-9f62-037a06af2f74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# use _RFHLTH as target variable, adjust to 0,1 for classifier\n",
    "df=df.withColumn(\n",
    "    'RFHLTH_adj',\n",
    "    when(df['_RFHLTH_clean'] == 1, 0).otherwise(\n",
    "        when(df['_RFHLTH_clean']==2,1).otherwise(df['_RFHLTH_clean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0be521b5-8229-4a0c-8545-da016ca4eb90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# make number of conditions column\n",
    "condition_cols=['CVDINFR4','CVDCRHD4','CVDSTRK3','ASTHMA3','CHCSCNC1','CHCOCNC1','CHCCOPD3','ADDEPEV3','CHCKDNY2','HAVARTH4','DIABETE4']\n",
    "df = df.withColumn(\n",
    "    'num_conditions',\n",
    "    sum(\n",
    "        when(col(c) == 1, 1).otherwise(0) # count conditions that are listed as 1\n",
    "        for c in condition_cols\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7650ea50-c687-4837-84a7-7eae0b4368ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next we will calculate income relative to poverty threshold. To do this we first make new variables with children capped at 8 and adults at 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0074c859-6682-4a4d-99e9-96af9682b09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    'CHILDREN_cap8',\n",
    "        when(df['CHILDREN_clean_mod'] >8, 8).otherwise(df['CHILDREN_clean_mod'])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c1401c0-ce2c-49e0-8476-9d2586ae8d75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    'ADULT_cap9',\n",
    "    when(df['HHADULT_clean']>9, 9).otherwise(df['HHADULT_clean'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e607e0a-fba8-4566-9a8e-8e700f4a6241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n|          ADULT_cap9| count|\n+--------------------+------+\n|                NULL| 81961|\n|                 1.0| 96588|\n|                 6.0|  2788|\n|                 4.0| 26067|\n|                 5.0|  8557|\n|                 8.0|   402|\n|5.397605346934028...|     1|\n|                 7.0|   911|\n|                 2.0|182543|\n|                 9.0|  4096|\n|                 3.0| 53756|\n+--------------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# check that cap function works\n",
    "df.groupBy('ADULT_cap9').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4a4ecdb-f281-4d60-be2c-364332429b90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we have capped variables, we read in the poverty data generated in the convert_census notebook and bin to match the BRFSS data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd8b4fcc-e767-4fbc-ba7c-37f21fee64d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "poverty_df = pd.read_csv('/Volumes/pophealthrisk/pophealthrisk/pophealthrisk/thresh24.csv')\n",
    "poverty_df=poverty_df.rename(columns={'household':'ADULT_cap9', 'children':'CHILDREN_cap8','threshold':'poverty_threshold'})\n",
    "bins=[0,10000,15000,20000,25000,35000,50000,75000,100000,150000,200000,np.inf]\n",
    "poverty_df['poverty_threshold_conv']=pd.cut(poverty_df['poverty_threshold'],bins, labels=[x for x in range(1,12)])\n",
    "poverty_df['poverty_threshold_conv']=pd.factorize(poverty_df['poverty_threshold_conv'])[0] + 2\n",
    "poverty_df = spark.createDataFrame(poverty_df) # convert to pyspark df for join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "598e8487-6c32-460a-a5ef-e03e655cb745",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Now we left join thresholds to the data\n",
    "df = df.join(poverty_df, on=['ADULT_cap9','CHILDREN_cap8'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e784f94-996b-438d-81db-28b95cb9f4ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------+\n|poverty_threshold_conv| count|\n+----------------------+------+\n|                  NULL|144700|\n|                     2| 79243|\n|                     7| 16199|\n|                     3|176715|\n|                     5|  3586|\n|                     4| 32908|\n|                     6|  4319|\n+----------------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('poverty_threshold_conv').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88d3e322-2260-4d1b-9850-1e26dc99094d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We can now calculate the income adjusted to the poverty threshold\n",
    "df = df.withColumn(\n",
    "    'income_adj_pov',\n",
    "    df['INCOME3_clean']-df['poverty_threshold_conv']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8922ca42-f7ac-4a4c-9ca0-337e14fc31ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Select features and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4765dc37-d25f-41ef-9731-ab660db5c87e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_min=df.select([\"_AGEG5YR_clean\",\"EDUCA_clean\",'_BMI5', '_SMOKER3_clean', 'DRNKANY6_clean','INCOME3_clean','num_conditions','income_adj_pov','RFHLTH_adj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10f76bf8-f199-425b-8169-5a11fe1eeb37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('_AGEG5YR_clean', 'double'),\n",
       " ('EDUCA_clean', 'double'),\n",
       " ('_BMI5', 'double'),\n",
       " ('_SMOKER3_clean', 'double'),\n",
       " ('DRNKANY6_clean', 'double'),\n",
       " ('INCOME3_clean', 'double'),\n",
       " ('num_conditions', 'int'),\n",
       " ('income_adj_pov', 'double'),\n",
       " ('RFHLTH_adj', 'double')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check types are as expected\n",
    "df_min.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11ee70e4-cf02-49fd-8111-c1d1afde5578",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+-----+--------------+--------------+-------------+--------------+--------------+----------+\n|_AGEG5YR_clean|EDUCA_clean|_BMI5|_SMOKER3_clean|DRNKANY6_clean|INCOME3_clean|num_conditions|income_adj_pov|RFHLTH_adj|\n+--------------+-----------+-----+--------------+--------------+-------------+--------------+--------------+----------+\n|          8310|       2363|43037|         32022|         43777|        87423|             0|        199183|      1310|\n+--------------+-----------+-----+--------------+--------------+-------------+--------------+--------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Count NA entries\n",
    "na_cols=[\"_AGEG5YR_clean\",\"EDUCA_clean\",'_BMI5', '_SMOKER3_clean', 'DRNKANY6_clean','INCOME3_clean','num_conditions','income_adj_pov','RFHLTH_adj']\n",
    "df_min.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in na_cols]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e39ea68-a724-4419-9bdf-510a0848c6f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229399\n457670\n"
     ]
    }
   ],
   "source": [
    "print(df_min.na.drop().count())\n",
    "print(df_min.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15815449-8159-4edb-be20-f0213976d996",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We lose a significant proportion of rows (1/2) when we require all values to be present. The 2 major contributors are INCOME3 and income_adj_pov, which derives from missing INCOME3 values and missing children/adults. A more thorough treatment could attempt to impute some of these values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f67f2b5d-4095-49cd-9547-8da57b1e4db6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_min=df_min.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c9f1afa-339c-49ff-96fa-4d482caf6ea2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n|RFHLTH_adj| count|\n+----------+------+\n|       0.0|185479|\n|       1.0| 43920|\n+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# This is a heavily skewed dataset, mostly healthy people\n",
    "df_min.groupBy('RFHLTH_adj').count().show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "transform_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
